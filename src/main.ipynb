{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet  : Find in translation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### chaque jour des dizaines d'objets sont perdus et retrouvés dans les gares parisiennes par les voyageurs, leur gestion est critique au niveau de la satisfaction client. Cependant le cout de leur gestion est critique également. On aimerait donc dimensionner au mieux le service en charge de les gérer mais pour cela il faut pouvoir anticiper de manière précise le volume d'objets trouvés chaque jour. Votre manager a une intuition qu'il aimerait vérifier: plus il fait froid plus les voyageurs sont chargés (manteau, écharppes, gant) plus ils ont donc de probabilité de les oublier. Mais empiler toutes ces couches prend du temps, ce qui pousse aussi à se mettre en retard et dans la précipitation, à oublier d'autres affaires encore. A l'aide des données de la SNCF et d'autres données, essayez de creuser cette piste."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Requeter la base de données des objets trouvés pour récupérer les données entre 2019 et 2022 sur les gares parisiennes et Stocker les données dans une BDD SQL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "\n",
    "url = \"https://ressources.data.sncf.com/api/records/1.0/search/?dataset=objets-trouves-restitution&q=gc_obo_gare_origine_r_name+%3D+%22Paris%22+AND+(date%3D'2019'+OR+date%3D'2020'+OR+date+%3D'2021'+OR+date%3D'2022')&sort=date&facet=date&facet=gc_obo_date_heure_restitution_c&facet=gc_obo_gare_origine_r_name&facet=gc_obo_nature_c&facet=gc_obo_type_c&facet=gc_obo_nom_recordtype_sc_c&timezone=Europe%2FParis&rows=-1\"\n",
    "\n",
    "\n",
    "response = requests.get(url)\n",
    "data = response.json()\n",
    "facet = data[\"parameters\"][\"facet\"]\n",
    "\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------------------\n",
    "# Extraire les valeurs de facet\n",
    "facets = facet\n",
    "date = facets[0]\n",
    "gc_obo_date_heure_restitution_c = facets[1]\n",
    "gc_obo_gare_origine_r_name = facets[2]\n",
    "gc_obo_nature_c = facets[3]\n",
    "gc_obo_type_c = facets[4]\n",
    "gc_obo_nom_recordtype_sc_c = facets[5]\n",
    "\n",
    "# Extraire les champs des enregistrements\n",
    "records = data[\"records\"]\n",
    "record_fields = []\n",
    "for record in records:\n",
    "    record_fields.append(record[\"fields\"])\n",
    "\n",
    "#print(record_fields)\n",
    "\n",
    "# Créer un DataFrame à partir des champs des enregistrements\n",
    "df = pd.DataFrame(record_fields)\n",
    "\n",
    "\n",
    "# Écrire le DataFrame dans un fichier CSV\n",
    "df.to_csv(\"objets-trouves.csv\", index=False)\n",
    "\n",
    "\n",
    "# Créer une connexion à la base de données\n",
    "connexion = sqlite3.connect('bdd.db')\n",
    "\n",
    "df.to_sql('objets_trouves', connexion,if_exists='replace', index=False)\n",
    "\n",
    "connexion.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "\n",
    "url = \"https://ressources.data.sncf.com/api/records/1.0/search/?dataset=objets-trouves-restitution&q=gc_obo_gare_origine_r_name+%3D+%22Paris%22+AND+(date%3D'2019'+OR+date%3D'2020'+OR+date+%3D'2021'+OR+date%3D'2022')&sort=date&facet=date&facet=gc_obo_date_heure_restitution_c&facet=gc_obo_gare_origine_r_name&facet=gc_obo_nature_c&facet=gc_obo_type_c&facet=gc_obo_nom_recordtype_sc_c&timezone=Europe%2FParis&rows=-1\"\n",
    "\n",
    "\n",
    "gares = ['Reims','Paris', 'Marseille', 'Lille', 'Rennes','Le Havre', 'Saint-Étienne', 'Toulon', 'Grenoble', 'Dijon', 'Angers', 'Nîmes', 'Villeurbanne','Lyon', 'Toulouse', 'Nice', 'Nantes', 'Strasbourg', 'Montpellier', 'Bordeaux']\n",
    "weather_data = pd.DataFrame(columns=[\"City\", \"Temperature\", \"Feels Like\", \"Min Temp\", \"Max Temp\", \"Pressure\", \"Humidity\", \"Wind Speed\", \"Wind Direction\", \"Sunrise\", \"Sunset\"])\n",
    "\n",
    "\n",
    "\n",
    "for g in gares:\n",
    "    api_url = url + \"appid=\" + API_KEY + \"&q=\" + city + \"&units=metric\" #API CALL \n",
    "    response = requests.get(api_url)   #Get method\n",
    "    data = response.json()\n",
    "    print(data)\n",
    "\n",
    "\n",
    "\n",
    "response = requests.get(url)\n",
    "data = response.json()\n",
    "facet = data[\"parameters\"][\"facet\"]\n",
    "\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------------------\n",
    "# Extraire les valeurs de facet\n",
    "facets = facet\n",
    "date = facets[0]\n",
    "gc_obo_date_heure_restitution_c = facets[1]\n",
    "gc_obo_gare_origine_r_name = facets[2]\n",
    "gc_obo_nature_c = facets[3]\n",
    "gc_obo_type_c = facets[4]\n",
    "gc_obo_nom_recordtype_sc_c = facets[5]\n",
    "\n",
    "# Extraire les champs des enregistrements\n",
    "records = data[\"records\"]\n",
    "record_fields = []\n",
    "for record in records:\n",
    "    record_fields.append(record[\"fields\"])\n",
    "\n",
    "#print(record_fields)\n",
    "\n",
    "# Créer un DataFrame à partir des champs des enregistrements\n",
    "df = pd.DataFrame(record_fields)\n",
    "\n",
    "\n",
    "# Écrire le DataFrame dans un fichier CSV\n",
    "df.to_csv(\"objets-trouves.csv\", index=False)\n",
    "\n",
    "\n",
    "# Créer une connexion à la base de données\n",
    "connexion = sqlite3.connect('bdd.db')\n",
    "\n",
    "df.to_sql('objets_trouves', connexion,if_exists='replace', index=False)\n",
    "\n",
    "connexion.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Requeter la base de données de Logtitude et Latitude et Stocker les données dans une BDD SQL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url_gares = \"https://ressources.data.sncf.com/api/records/1.0/search/?dataset=referentiel-gares-voyageurs&q=&sort=gare_alias_libelle_noncontraint&rows=-1\"\n",
    "\n",
    "\n",
    "response = requests.get(url_gares)\n",
    "\n",
    "data_list = []\n",
    "\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    for record in data['records']:\n",
    "        gare_alias_libelle_noncontraint = record['fields']['gare_alias_libelle_noncontraint']\n",
    "        if 'wgs_84' in record['fields']:\n",
    "            latitude = record['fields']['wgs_84'][0]\n",
    "            longitude = record['fields']['wgs_84'][1]\n",
    "            data_list.append([gare_alias_libelle_noncontraint, latitude, longitude])\n",
    "\n",
    "            \n",
    "else:\n",
    "    print(\"Une erreur s'est produite lors de la requête à l'API.\")\n",
    "    \n",
    "df_data = pd.DataFrame(data_list, columns=[\n",
    "    \"Gare\",\n",
    "    \"Latitude\",\n",
    "    \"Longitude\"\n",
    "])\n",
    "\n",
    "df_data.to_csv('df_data.csv')\n",
    "\n",
    "import sqlite3\n",
    "import pandas as pd \n",
    "\n",
    "connexion = sqlite3.connect('bdd.db')\n",
    "\n",
    "df_data.to_sql('coordonnees_gares', connexion,if_exists='replace', index=False)\n",
    "\n",
    "connexion.close()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Requeter la base de données de la température et Stocker les données dans une BDD SQL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine-learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ce8263f54646eff212f75d029976341b1907292128b7f9fc9935844628a6029c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
